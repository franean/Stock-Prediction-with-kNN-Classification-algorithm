import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from pandas_datareader import data as pdr
import fix_yahoo_finance as yf

df=pdr.get_data_yahoo('SPY','2012-01-01','2017-01-01')
df=df.dropna()
df=df[['Open','High','Low','Close']]

df['Open - Close'] = df.Open-df.Close
df['High - Low']=df.High-df.Low
df=df.dropna()

X = df[['Open - Close', 'High - Low']]

# target variable
y = np.where(df['Close'].shift(-1)>df['Close'], 1, -1)
#splitting the dataset:
split_percentage = 0.75
split = int(split_percentage*len(df))

X_train = X[:split]
y_train = y[:split]

X_test = X[split:]
y_test = y[split:]

training_accuracy = []
testing_accuracy = []


neighbors_settings = range(1, 501)

for n_neighbors in neighbors_settings:
    clf = KNeighborsClassifier(n_neighbors = n_neighbors)
    clf.fit(X_train, y_train)
    #record training set accuracy
    training_accuracy.append(clf.score(X_train, y_train))
    #record generalization accuracy
    testing_accuracy.append(clf.score(X_test, y_test))
    
plt.plot(neighbors_settings, training_accuracy, label = "training accuracy")
plt.plot(neighbors_settings, testing_accuracy, label = "test accuracy")
plt.ylabel("Accuracy")
plt.xlabel("n_neighbors")
plt.legend()
plt.show()

#from the above graph you can find the optimum value of k
# I got bout 56% accuracy with k=63 for SPY
